# Items.py

##  一、**解析 Facebook 页面中的时间字符串**（英文版 `parse_date2` 函数）

这个函数是项目中最关键的内容之一，用于将 Facebook 上显示的各种英文时间格式（如“5 hours ago”“Aug 25, 2016 at 7:00 PM”）标准化为 Python 的 `datetime.date` 类型。

### 支持的时间格式包括：

- 相对时间（如：`yesterday`, `now`, `5 hours ago`, `50 mins ago`）
- 简单日期（如：`2 Jan`, `January 2`, `Jul 11, 2016`）
- 带星期和时间的格式（如：`Thursday at 4:27 PM`, `Jan 29 at 10:00 PM`）
- 完整日期带时间（如：`Aug 25, 2016 at 7:00 PM`）

它能判断是否为“昨天”的场景，如时间戳落在当天0点前并向前推一天。

------

## 📦 二、**定义 4 个 Scrapy Item 数据结构类**

Scrapy 的 `Item` 类用于描述要从网页中提取的字段。这些类定义了字段名称和清洗函数（`output_processor`）。

### 1. `FbcrawlItem`（用于 Facebook 帖子）：

- 包含：内容 `text`、发布时间 `date`、评论数 `comments`、点赞数和各种反应（love、wow 等）、分享数、URL、帖子的 ID、是否转发。
- 使用处理器进行字段清洗，如 `Join()`、`comments_strip()` 等。

### 2. `CommentsItem`（用于评论）：

- 包含评论内容、发表时间、点赞、反应、评论人、来源帖。

### 3. `ProfileItem`（用于用户个人资料）：

- 包含用户名、性别、生日、所在城市、家乡、工作、教育、兴趣对象等。

### 4. `EventsItem`（用于活动事件）：

- 包含活动名、位置、照片、起止时间、描述等字段。

------

## 🧼 三、**字段的清洗与处理函数引用**

比如：

- `Join(separator=u'')`：将文本合并为单个字符串
- `comments_strip`、`reactions_strip`、`url_strip`、`id_strip`：都是自定义的数据清洗函数，用于标准化原始字段值（比如从嵌套结构中提取评论数、ID等）

------

## ✅ 总结一句话：

> 这个文件是 `fbcrawl` 项目的“**数据定义与预处理中心**”，用于解析 Facebook 的日期格式、定义帖子、评论、个人信息和活动信息的结构，并指定这些字段的清洗规则，帮助爬虫将复杂网页数据转化为结构化、标准化的数据，方便后续保存和分析。